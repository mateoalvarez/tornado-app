# Home page

"welcome","welcome"
"Welcome","Welcome"
"Sign out","Sign Out"
"home.cards.header.create_user","Register"
"home_cards_text_create_user","Create an account and enter your Twitter credentials. For more information, visit this "

"home.cards.header.upload_dataset","Use your data"
"home.cards.text.upload_dataset","Load your datasets in the platform to train models or use public datasets already loaded."

"home.cards.header.create_model","Train Models"
"home.cards.text.create_model","Train models within a cluster, from distributed, based on the data loaded."

"home.cards.header.deploy_application","Deploy Applications"
"home.cards.text.deploy_application","Use models already trained to deploy applications connected to the Twitter API in order to classify and store Tweets."

"home.cards.header.visualize_data","Visualize and download data"
"home.cards.text.visualize_data","Analyse tendency graphs in order to see the Tweets’ classification and download their data."

## Landing page

### First section
"landing.main.title","PyxisML"
"landing.main.description","The Machine Learning tool that classifies tweets in real time"
"landing.main.read_more.button","How does it work?"

### Second section
"landing.steps.first_step.header","Register"
"landing.steps.first_step.paragraph","Create an account and introduce your Twitter credentials"
"landing.steps.first_step.button","Register"
"landing.steps.second_step.header","Train a Model"
"landing.steps.second_step.paragraph","Train a model using one of our datasets or your own dataset."
"landing.steps.second_step.button","Train"
"landing.steps.third_step.header","Classify Tweets"
"landing.steps.third_step.paragraph","Create an application, chose a hashtag and classify Tweets that contain that hashtag"
"landing.steps.third_step.button","Classify"
"landing.steps.fourth_step.header","Check Results"
"landing.steps.fourth_step.paragraph","Monitorize in real time the classification of Tweets and download the data to make your own analysis."
"landing.steps.fourth_step.button","Visualize"

### Third section
"landing.how_it_works.header","How does it work"
"landing.how_it_works.description","We use NLP (Natural Language Processing) algorithms together with other Machine Learning techniques to generate models that allow us to classify Tweets as positive or negative. We then deploy these models and connect them with the Twitter API in order to obtain a stream of classified Tweets and store them within our database so we can later analyse them."
"landing.how_it_works.advantages.first.header","Es muy fácil"
"landing.how_it_works.advantages.first.paragraph","Programming is not necessary as the code is already generated and the training and deployment of models is done through clicks."
"landing.how_it_works.advantages.second.header","In real time"
"landing.how_it_works.advantages.second.paragraph","Applications connect to the Twitter API. They download and classify Tweets in real time and therefore you obtain your results instantaneously. Furthermore you are able to monitorize external events."
"landing.how_it_works.advantages.third.header","Download the data"
"landing.how_it_works.advantages.third.paragraph","Appart from the visualization, you can also download data from classified Tweets as well as previously generated models so you may use them as you please."
"landing.how_it_works.advantages.fourth.header","Growing platform"
"landing.how_it_works.advantages.fourth.paragraph","Pyxisml is a platform in constant growth so we will keep adding new functionality progressively as well as new models and methodologies."



# Navbar

"navbar.user.Login","Login"
"navbar.user.Logout","Logout"
"navbar.user.Register","Registration"
"navbar.user.Settings","Configuration"
"navbar.datasets","Datasets"
"navbar.pipelines","Pipelines"
"navbar.applications","Applications"

# Pipelines

"pipelines.upload_dataset.header","Load a Dataset"
"pipelines.upload_dataset.body","Load your own datasets or use public datasets in order to train your models"
"pipelines.upload_dataset.button","Load dataset"

"pipelines.create_pipeline.header","Train a pipeline"
"pipelines.create_pipeline.body","Build and train pipelines to use them for Tweet classification"
"pipelines.create_pipeline.button","Create a pipeline"

"pipelines.create_application.header","Create an Application"
"pipelines.create_application.body","Create an application from a pipeline to obtain and classify Tweets in real time"
"pipelines.create_application.button","Create Application"




# Datasets

"datasets.main.description","Here you can manage your datasets, as well as download the public ones provided. The format of the dataset must be tsv (tab separated values), with the following structure: <text> tab <numeric label>, ie: text to classify  1.0"
"datasets.headers.public_datasets","Public Datasets"
"datasets.headers.user_datasets","Private Datasets"
"datasets.no.public.datasets","There are no public datasets yet"
"datasets.no.private.datasets","There are no private datasets yet"

## Upload Datasets

"datasets.upload.dataset","Load Dataset"
"datasets.upload.description","Dataset Description"
"datasets.upload.properties","Dataset Properties"

## Manage Datasets
"datasets.header.dataset_description","Dataset Description"
"datasets.header.dataset_properties","Dataset Properties"
"datasets.delete.button","Delete Dataset: "
"datasets.download_link","Download this dataset"

### Manage Datasets Modal

"datasets.delete.confirm.title","Confirm Deletion"
"datasets.delete.confirm.confirmation_text","This action cannot be undone, please confirm deletion: "
"datasets.delete.confirm.go_back","Go Back"
"datasets.delete.confirm.confirm","Confirm"

# User login

"login.user.Email","Email"
"login.user.Password","Password"
"login.user.Login","Enter"

# User registration

"registration.user.Email","Email"
"registration.user.Username","Name"
"registration.user.Password","Password"
"registration.user.Repeatpassword","Repeat password"
"registration.user.Register","Register"

# User settings page

"user.settings.title","Settings"
"user.settings.name","Name"
"user.settings.email","Email"
"user.settings.type","Type"

# Pipelines

## Tabs
"mlmodels.tab.Datapreprocessing","Preprocessing"
"mlmodels.tab.Modelsselection","Models"
"mlmodels.tab.create_pipeline","Create pipeline"
"mlmodels.tab.pipelines","Pipelines"

### Preprocessing tab
"pipelines.tab.data_preprocessing","Preprocessing stages"
"pipelines.header.data_prep_method_description","Description"

### Models tab
"pipelines.tab.models","Models"
"pipelines.header.model_description","Description"

### Pipeline creation tab
"mlmodels.tab.pipeline_creation","Create new pipeline"
"models.pipeline_creation.select.dataset","Select dataset"
"models.pipeline_creation.select.preprocessing","Add preprocessing stages"
"models.pipeline_creation.select.model","Add models"
"models.pipeline_creation.select.classification_criteria","Choose classification criteria"
"models.pipeline_creation.select.pipeline_name","Pipeline name"
"models.pipeline_creation.select.preprocessing.stage.preprocessing","Template"
"models.pipeline_creation.select.preprocessing.stage.config","Configuration"
"models.pipeline_creation.select.preprocessing.stage.add_more","Add more preprocessing stages"
"models.pipeline_creation.select.preprocessing.stage.delete_current","Delete preprocessing stage"
"models.pipeline_creation.select.preprocessing.stage.config.description",Introduce configuration with the format: {"key":"value"}
"models.pipeline_creation.select.model.stage.model","Template"
"models.pipeline_creation.select.model.stage.config","Configuration"
"models.pipeline_creation.select.model.stage.add_more","Add more models"
"models.pipeline_creation.select.model.stage.delete_current","Delete models"
"models.pipeline_creation.select.model.stage.config.description",Introduce configuration with the format: {"key":"value"}
"models.pipeline_creation.submit","Create pipeline"


### Pipeline status tab
"models.header.pipeline_name","Name"
"models.header.dataset","Dataset"
"models.header.preprocessing_stages","Preprocessing stages"
"models.header.models","Models"
"models.header.classification_criteria","Classification criteria"
"models.header.status","Status"
"models.header.start_training","Start training"
"models.content.start_training","Start training"
"models.header.delete","Delete"
"models.content.delete_model","Delete"
"application.tab.pipelines","Pipelines"

"models.deploy.confirm.confirmation_text","The application will deploy a spark work within a distributed cluster, which will generate additional costs. Are you sure you want to continue?"

# APPLICATION DEPLOY

## Applications
"applications.header","Applications"

## Application cards
"applications.user_applications.card_navbar.application_status","Application"
"applications.user_applications.card_navbar.application_visualization","Data"

## Application management
"application.tab.applications","Applications"
"application.tab.create_application","Create Application"
"applications.user_applications.deploy_application","Deploy application"
"applications.user_applications.delete_application_deployment","Stop application"
"applications.user_applications.delete_application","Delete Application"
"applications.user_applications.no_applications.header","There are no applications"

## Create applications
"applications.create_application.create_form.reveal_button","Create applications"
"applications.create_application.create_form.header","New application"
"applications.create_application.create_form.application_name","Name"
"applications.create_application.create_form.select_pipeline","Pipeline Selection"
"applications.create_application.create_form.keywords","Keywords"
"create_application.create_form.keywords_placeholder","bigdata,ai"
"create_application.create_form.submit_form","create application"
"create_application.create_form.optgroup_label.user_pipelines","--- Private Pipelines ---"
"create_application.create_form.optgroup_label.public_pipelines","--- Public Pipelines ---"

## Application deploy
"applications.header.deploy","Deploy "
"applications.content.deploy","Deploy "
"applications.header.delete","Stop"
"applications.content.delete","Stop"
"applications.deploy.confirm.confirmation_text","The application will deploy within the cluster and will classify Tweets received from Twitter. Enter the keywords (hashtags) that you want to monitorize. Keywords must be separated by commas(,), spaces are not allowed and they are processed as filters ‘OR’"
"applications.delete.confirm.confirmation_text","The application will stop which will interrupt the processing of new data. Already processed data will still be available."

## Application visualization data
"applications.user_applications.card_body.visualize","Visualization"
"applications.user_applications.card_body.download","Download data"
